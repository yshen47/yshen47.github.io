

<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>SGAM</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                SGAM: Building a Virtual 3D World through Simultaneous Generation and Mapping</br> 
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://yshen47.github.io/" target="_blank" rel="noopener noreferrer">
                          Yuan Shen \(^{1}\)
                        </a>
                    </li>
                    <li>
                        <a href="https://people.csail.mit.edu/weichium/" target="_blank" rel="noopener noreferrer">
                            Wei-Chiu Ma \(^{2}\)
                        </a>
                    </li>
                    <li>
                        <a href="https://shenlong.web.illinois.edu/" target="_blank" rel="noopener noreferrer">
                          Shenlong Wang \(^1\)
                        </a>
                    </li>
                </ul>
            </div>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        \(^1\) University of Illinois at Urbana-Champaign
                    </li>
                    <li>
                        \(^2\) Massachusetts Institute of Technology
                    </li>
                </ul>
            </div>
        </div>
        <div class="row">
            <h2 class="col-md-12 text-center">
                <small>
                    NeurIPS 2022
                </small>
            </h2>
        </div>

        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://openreview.net/pdf?id=17KCLTbRymw" target="_blank" rel="noopener noreferrer">
                            <image src="../img/sgam_paper_cover.png" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://www.youtube.com/watch?v=GrtooGn_Rws" target="_blank" rel="noopener noreferrer">
                            <image src="../img/youtube_icon.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/yshen47/SGAM" target="_blank" rel="noopener noreferrer">
                            <image src="../img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://colab.research.google.com/drive/1nW5oHKsb0e01BdFU-EjsNqJmQNNo294h?usp=sharing" target="_blank" rel="noopener noreferrer">
                            <image src="../img/colab.png" height="60px">
                                <h4><strong>Colab Quickstart</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>

        <!-- Abstraction, Overview figure-->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <div class="text-center">
                    <video width="800" height="267" autoplay loop controls>
                              <source src="diversity_video/teaser.mp4" type="video/mp4">
                              Your browser does not support the video tag.
                    </video>
                </div><br> 
                
                <h3>
                    TL;DR
                </h3>
                <p class="text-justify">
                    Our goal is to generate a large-scale 3D world from a single RGB-D inital pose. We present a new 3D scene generation framework that simultaneously generates sensor data at novel viewpoints and builds a 3D map. 
                    Our framework is illustrated in the diagram below. The GIF animation above is generated via SGAM with only the first RGB-D frame known.
                </p>
                <div class="text-center">
                    <image src="diversity_video/overview_gif.gif" class="img-responsive" alt="overview">
                </div><br> 
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    We present simultaneous generation and mapping (SGAM), a novel 3D scene generation algorithm. Our goal is to produce a 
                    realistic, globally consistent 3D world on a large scale. Achieving this goal is challenging and goes beyond the capacities 
                    of existing 3D generation or video generation approaches, which fail to scale up to create large, globally consistent 3D 
                    scene structures. Towards tackling the challenges, we take a hybrid approach that integrates generative sensor modeling 
                    with 3D reconstruction. Our proposed approach is an autoregressive generative framework that simultaneously generates 
                    sensor data at novel viewpoints and builds a 3D map at each timestamp. Given an arbitrary camera trajectory, our method 
                    repeatedly applies this generation-and-mapping process for thousands of steps, allowing us to create a gigantic virtual world. 
                    Our model can be trained from RGB-D sequences without having access to the complete 3D scene structure. The generated scenes 
                    are readily compatible with various interactive environments and rendering engines. Building upon the CLEVR dataset, we propose 
                    a large-scale 3D scene generation benchmark, CLEVR-Infinite dataset, and demonstrate ours can generate consistent, realistic, 
                    and geometrically-plausible scenes that compare favorably to existing view synthesis methods. 
                </p>
                
            </div>
        </div>

        <!-- Video -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe width="900" height="300" src="https://www.youtube.com/watch?v=GrtooGn_Rws" style="position:absolute;top:0;left:0;width:100%;height:100%;" frameborder="0" ></iframe>
                    </div>
                </div><br> 
            </div>
        </div>
        
        <!-- Results -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results on our CLEVR-Infinite Dataset
                </h3>
                <p class="text-justify">
                    The following videos are 3D scene examples sampled by varying trajectory orders. 
                </p>                
                <div class="col-md-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <h4><strong>Column-Major</strong></h4>
                            <video width="267" height="150" autoplay loop controls>
                              <source src="diversity_video/CLEVR-Infinite-column.mp4" type="video/mp4">
                              Your browser does not support the video tag.
                            </video>
                        </li>
                        <li>
                            <h4><strong>Row-Major</strong></h4>
                            <video width="267" height="150" autoplay loop controls>
                              <source src="diversity_video/CLEVR-Infinite-row.mp4" type="video/mp4">
                              Your browser does not support the video tag.
                            </video>
                            
                        </li>
                        <li>
                            <h4><strong>Zigzag</strong></h4>
                            <video width="267" height="150" autoplay loop controls>
                              <source src="diversity_video/CLEVR-Infinite-zigzag.mp4" type="video/mp4">
                              Your browser does not support the video tag.
                            </video>
                            
                        </li>
                        <br>
                        <li>
                            <h4><strong>Greedy</strong></h4>
                            <video width="267" height="150" autoplay loop controls>
                              <source src="diversity_video/CLEVR-Infinite-greedy.mp4" type="video/mp4">
                              Your browser does not support the video tag.
                            </video>
                        </li>
                        <li>
                            <h4><strong>Ring</strong></h4>
                            <video width="267" height="150" autoplay loop controls>
                              <source src="diversity_video/CLEVR-Infinite-ring.mp4" type="video/mp4">
                              Your browser does not support the video tag.
                            </video>
                        </li>
                        <li>
                            <h4><strong>Spiral</strong></h4>
                            <video width="267" height="150" autoplay loop controls>
                              <source src="diversity_video/CLEVR-Infinite-spiral.mp4" type="video/mp4">
                              Your browser does not support the video tag.
                            </video>
                        </li>
                        <br>
                        <li>
                            <img src="diversity_video/google_earth_256x256_demo1.gif" width="267" />
                        </li>
                        <li>
                            <img src="diversity_video/ezgif.com-gif-maker (1).gif" width="267" />
                        </li>
                    </ul>
                </div>

            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results on our GoogleEarth-Infinite Dataset
                </h3>
                <p class="text-justify">
                    The following are color point cloud visualization of the global mapping from four generated 3D scenes.
                </p>
                <image src="../img/global_mapping.png" class="img-responsive" alt="global_mapping" /><br>
                
                <p class="text-justify">
                    The following videos are 3D scene GIF examples sampled with different initial RGB-D images. 
                </p>
                <br>
                <div class="col-md-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <img src="diversity_video/google_earth_256x256_demo3.gif" width="267" />
                        </li>
                        <li>
                            <img src="diversity_video/google_earth_256x256_demo1.gif" width="267" />
                        </li>
                        <li>
                            <img src="diversity_video/ezgif.com-gif-maker (1).gif" width="267" />
                        </li>
                    </ul>
                </div>
                <br>
            </div>
        </div>
            
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly style="height: 150px">
@inproceedings{
shen2022sgam,
title={{SGAM}: Building a Virtual 3D World through Simultaneous Generation and Mapping},
author={Yuan Shen and Wei-Chiu Ma and Shenlong Wang},
booktitle={Thirty-Sixth Conference on Neural Information Processing Systems},
year={2022},
url={https://openreview.net/forum?id=17KCLTbRymw}
}
                    </textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    We thank <a href="https://www.zyrianov.org/">Vlas Zyrianov</a> for his feedback on our paper drafts. 
                    Besides, our codebase is modified on top of <a href="https://github.com/CompVis/taming-transformers">VQGAN codebase</a>. Many thanks to Patrick Esser and Robin Rombach, who makes their code available.
                    
                </p>
            </div>
        </div>
    </div>
</body>
</html>
